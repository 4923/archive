{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"DHG\"\n",
    "> [Deep Hyper Graph](https://deephypergraph.com/#/)\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- keywords : Library, Graph, HyperGraph\n",
    "- categories: [Graph, HyperGraph]\n",
    "- permalink: /deep-hyper-graph/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installation guide\n",
    "- [docs/install](https://deephypergraph.readthedocs.io/en/0.9.3/start/install.html)\n",
    "\n",
    "\n",
    "```py\n",
    "# conda env : python 3.8\n",
    "$ pip install dhg\n",
    "\n",
    "# dependencies / requirements\n",
    "$ conda install -c pytorch pytorch    # (최신버전 설치) dhg는 torch를 확장한 패키지, (23.03 현재 m1 가속을 지원한다.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:2.0.0\n",
      "MPS supportive build? : True\n",
      "MPS available : True\n",
      "macOS-13.0-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "# for M1 MAC / pytorch check\n",
    "\n",
    "import torch; device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch version:{torch.__version__}\") # 1.12.1 이상\n",
    "print(f\"MPS supportive build? : {torch.backends.mps.is_built()}\")\n",
    "print(f\"MPS available : {torch.backends.mps.is_available()}\")\n",
    "!python -c 'import platform;print(platform.platform())'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooking200 Example\n",
    "\n",
    "> The Cooking 200 dataset (dhg.data.Cooking200) is collected from Yummly.com for vertex classification task. It is a hypergraph dataset, in which vertex denotes the dish and hyperedge denotes the ingredient. Each dish is also associated with category information, which indicates the dish’s cuisine like Chinese, Japanese, French, and Russian.\n",
    "\n",
    "> Kaggle [https://www.kaggle.com/c/whats-cooking](https://www.kaggle.com/c/whats-cooking) 에서 공개된 데이터셋이다.\n",
    "> CLI환경에서는 `kaggle competitions download -c whats-cooking` 으로 다운로드 가능하며 train.json은 id:int, cuisine:int,ingredients:list 구조로 구성되어있다.\n",
    "\n",
    "graph dataset은 cora, pubmed 등 논문과 논문의 저자 관계를 다룬 데이터셋을 사용하는게 일반적이지만 hypergraph dataset은 그보다 조금 더 복잡한, 다수의 관계를 매핑한 데이터셋을 사용한다. `Yummly` 에서 제작한 데이터셋인 Cooking200의 구조는 아래와 같다.\n",
    "- vertex (=node) : dish, receipt\n",
    "- hyperedge (node 간의 관계) : ingredient\n",
    "    - hyperedge: A connection between two or more vertices of a hypergraph. A hyperedge connecting just two vertices is simply a usual graph edge.\n",
    "    - G는 결국 HG의 특수한 형태로, hyperedge를 edge의 확장으로 생각하는 것 보다 hyperedge의 특수한 경우를 edge로 이해하는 편이 빠르다. 결국 **edge는 node간의 관계를 의미하는 용어**이고 일반 graph에서 edge는 1:1 관계, hypergraph에서의 edge, 즉 hyperedge는 다수간의 연결을 의미한다.\n",
    "\n",
    "Cooking200은 크게 요리(dish), 분류(category), 재료(ingredient) 로 구분되는데, 각 재료는 한가지 요리에 종속되지 않으며 \n",
    "\n",
    "#### NOTE\n",
    "1. The dataset is a hypergraph dataset, which cannot be directly used for GCN model. Thus, `the clique expansion is adpoted` to reduce the hypergraph structure to a graph structure.\n",
    "    - GCN 구조상 A를 만들지 않고서는 GCN에 hypergraph dataset을 사용할 수 없다.\n",
    "    - expansion의 경우 `dhg` 에서 제공하는 기능으로 구현할 수 있는데 이는 다음 [공식문서](https://deephypergraph.readthedocs.io/en/latest/tutorial/structure.html#reduced-from-high-order-structures)를 참고 할 것. star expansion, clique expansion, hypergcn* 의 방법을 지원한다.\n",
    "        - *hypergcn : ('In the HyperGCN paper, the authors also describe a method to reduce the hyperedges in the hypergraph to the edges in the graph as the following figure.')\n",
    "        ![hypergraph from hypergcn](https://deephypergraph.readthedocs.io/en/latest/_images/hypergcn.png)\n",
    "2. The dataset `do not contain the vertex features`. Thus, we generate a identity matrix for vertex features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/hypergraph-py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/hypergraph-py38/lib/python3.8/site-packages/dhg/structure/graphs/graph.py:247: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1678455016227/work/aten/src/ATen/SparseCsrTensorImpl.cpp:56.)\n",
      "  adj = miu * hypergraph.H.mm(hypergraph.H_T).coalesce().cpu().clone()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Time: 7.83699s, Loss: 3.02474\n",
      "update best: 0.05000\n",
      "Epoch: 1, Time: 0.22393s, Loss: 2.47472\n",
      "Epoch: 2, Time: 0.21954s, Loss: 2.41068\n",
      "\n",
      "train finished!\n",
      "best val: 0.05000\n",
      "test...\n",
      "final result: epoch: 0\n",
      "{'accuracy': 0.01942024938762188, 'f1_score': 0.0019050287155063736, 'f1_score -> average@micro': 0.019420248464943595}\n"
     ]
    }
   ],
   "source": [
    "# Example : https://deephypergraph.readthedocs.io/en/latest/examples/vertex_cls/hypergraph.html#gcn-on-cooking200\n",
    "\n",
    "'''Import libraries'''\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dhg import Graph, Hypergraph\n",
    "from dhg.data import Cooking200\n",
    "from dhg.models import GCN\n",
    "from dhg.random import set_seed\n",
    "from dhg.metrics import HypergraphVertexClassificationEvaluator as Evaluator\n",
    "\n",
    "'''Define Functions'''\n",
    "\n",
    "def train(net, X, A, lbls, train_idx, optimizer, epoch):\n",
    "    net.train()\n",
    "\n",
    "    st = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    outs = net(X, A)\n",
    "    outs, lbls = outs[train_idx], lbls[train_idx]\n",
    "    loss = F.cross_entropy(outs, lbls)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Time: {time.time()-st:.5f}s, Loss: {loss.item():.5f}\")\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer(net, X, A, lbls, idx, test=False):\n",
    "    net.eval()\n",
    "    outs = net(X, A)\n",
    "    outs, lbls = outs[idx], lbls[idx]\n",
    "    if not test:\n",
    "        res = evaluator.validate(lbls, outs)\n",
    "    else:\n",
    "        res = evaluator.test(lbls, outs)\n",
    "    return res\n",
    "\n",
    "'''Main'''\n",
    "if __name__ == \"__main__\":\n",
    "    set_seed(2021)\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    evaluator = Evaluator([\"accuracy\", \"f1_score\", {\"f1_score\": {\"average\": \"micro\"}}])\n",
    "    data = Cooking200()\n",
    "\n",
    "    X, lbl = torch.eye(data[\"num_vertices\"]), data[\"labels\"]\n",
    "    ft_dim = X.shape[1]\n",
    "    HG = Hypergraph(data[\"num_vertices\"], data[\"edge_list\"])\n",
    "    G = Graph.from_hypergraph_clique(HG, weighted=True)\n",
    "    train_mask = data[\"train_mask\"]\n",
    "    val_mask = data[\"val_mask\"]\n",
    "    test_mask = data[\"test_mask\"]\n",
    "\n",
    "    net = GCN(ft_dim, 32, data[\"num_classes\"], use_bn=True)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    X, lbl = X.to(device), lbl.to(device)\n",
    "    G = G.to(device)\n",
    "    net = net.to(device)\n",
    "\n",
    "    best_state = None\n",
    "    best_epoch, best_val = 0, 0\n",
    "    for epoch in range(3):        # 200 epoch -> 3 으로 줄여서 테스트\n",
    "        # train\n",
    "        train(net, X, G, lbl, train_mask, optimizer, epoch)\n",
    "        # validation\n",
    "        if epoch % 1 == 0:\n",
    "            with torch.no_grad():\n",
    "                val_res = infer(net, X, G, lbl, val_mask)\n",
    "            if val_res > best_val:\n",
    "                print(f\"update best: {val_res:.5f}\")\n",
    "                best_epoch = epoch\n",
    "                best_val = val_res\n",
    "                best_state = deepcopy(net.state_dict())\n",
    "    print(\"\\ntrain finished!\")\n",
    "    print(f\"best val: {best_val:.5f}\")\n",
    "    # test\n",
    "    print(\"test...\")\n",
    "    net.load_state_dict(best_state)\n",
    "    res = infer(net, X, G, lbl, test_mask, test=True)\n",
    "    print(f\"final result: epoch: {best_epoch}\")\n",
    "    print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API structures & references\n",
    "\n",
    "- docs 참고, 주요 구조 기록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abed52475ed3bc7fd4b3a08ba8fb8e39988a48d39d6838c1be2ad28d8cd28fcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
